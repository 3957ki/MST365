{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë©”ì¸ ë¡œì§\n",
    "ì‚¬ìš©ìë¡œë¶€í„° ì‹œë‚˜ë¦¬ì˜¤ í”„ë¡¬í”„íŠ¸ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ì•¼ í•¨.\n",
    "ê·¸ë¦¬ê³  ë¹Œë“œ ë²ˆí˜¸ë„ ë°›ì•„ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ë¨: 1.png\n",
      "ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ./results\\20250423-111510_report_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in sse_reader: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Any\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, max_tokens=4000)\n",
    "\n",
    "# MCP í´ë¼ì´ì–¸íŠ¸\n",
    "client = MultiServerMCPClient({\n",
    "    \"playwright\": {\n",
    "        \"url\": \"http://localhost:8005/sse\",\n",
    "        \"transport\": \"sse\",\n",
    "    }\n",
    "})\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "BASE_DIR = \"./results\"\n",
    "build_num = 1   # ì„ì‹œë¡œ ë¹Œë“œ numberê°€ 1\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "test_id = f\"{timestamp}_report_{build_num}\"\n",
    "output_dir = os.path.join(BASE_DIR, test_id)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Output Parser\n",
    "class FailedStep(BaseModel):\n",
    "    num: int\n",
    "    message: str\n",
    "\n",
    "class WebTestResult(BaseModel):\n",
    "    status: bool\n",
    "    duration: Optional[float]\n",
    "    feedback: str\n",
    "    fail: Optional[List[FailedStep]]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=WebTestResult)\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ë‹¤ìŒ ì›¹ ìë™í™” í…ŒìŠ¤íŠ¸ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì•„ë˜ í˜•ì‹ì˜ JSONìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n",
    "\n",
    "- status: í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€ (true/false)\n",
    "- duration: í…ŒìŠ¤íŠ¸ ì†Œìš” ì‹œê°„ (ì´ˆ ë‹¨ìœ„, ìˆ«ì)\n",
    "- feedback: ì „ì²´ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ìš”ì•½ í”¼ë“œë°±\n",
    "- fail: ì‹¤íŒ¨í•œ ë™ì‘ì´ ìˆì„ ê²½ìš°,\n",
    "  - ì‹¤íŒ¨í•œ \"ìŠ¤í… ë²ˆí˜¸\" (ì…ë ¥ ì‹œë‚˜ë¦¬ì˜¤ stepsì—ì„œ ëª‡ ë²ˆì§¸ stepì¸ì§€, ì˜ˆ: 2ë²ˆ stepì´ë©´ num: 2),\n",
    "  - ì‹¤íŒ¨ ì´ìœ ë¥¼ messageì— ë‹´ì•„ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±í•  ê²ƒ\n",
    "\n",
    "âš ï¸ ì£¼ì˜:\n",
    "- â€˜ì‹¤íŒ¨â€™ ë˜ëŠ” â€˜ì˜ë„í•œ í–‰ë™ê³¼ ë‹¤ë¥¸ ê²°ê³¼â€™ê°€ ìˆì—ˆë‹¤ë©´ ë°˜ë“œì‹œ fail í•­ëª©ì„ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.\n",
    "- \"ì‹¤íŒ¨í•œ ê²ƒ ê°™ì§€ë§Œ ì¼ë‹¨ ì„±ê³µ\"ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´ í´ë¦­ì´ ë‹¤ë¥¸ ëŒ€ìƒì— ì˜ëª» ì ìš©ë˜ë©´ ë¬´ì¡°ê±´ ì‹¤íŒ¨ë¡œ ê°„ì£¼í•˜ê³  fail ë¦¬ìŠ¤íŠ¸ì— í¬í•¨í•˜ì„¸ìš”.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ë¡œê·¸:\n",
    "{raw_result}\n",
    "\"\"\",\n",
    "    input_variables=[\"raw_result\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "summary_chain: Runnable = summary_prompt | model | parser\n",
    "\n",
    "DEFAULT_RESULT_STEP = \"ì„±ê³µ ì—¬ë¶€, ì†ë„, í”¼ë“œë°±ì„ í¬í•¨í•´ ê²°ê³¼ë¥¼ ìš”ì•½í•œë‹¤.\"\n",
    "\n",
    "# ì‹œë‚˜ë¦¬ì˜¤ ë‹¨ìœ„ ì‹¤í–‰\n",
    "async def run_test():\n",
    "    await client.__aenter__()\n",
    "    tools = client.get_tools()\n",
    "\n",
    "    scenarios = [\n",
    "        # {\n",
    "        #     \"title\": \"ë„¤ì´ë²„ ê²€ìƒ‰ ê¸°ëŠ¥ í™•ì¸\",\n",
    "        #     \"steps\": [\n",
    "        #         \"https://naver.com ì— ì ‘ì†í•œë‹¤.\",\n",
    "        #         \"ê²€ìƒ‰ì°½ì— SSAFYë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰ë²„íŠ¼ì„ ëˆ„ë¥¸ë‹¤.\",\n",
    "        #         \"SSAFYì™€ ê´€ë ¨ëœ ê²Œì‹œë¬¼ì´ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•œë‹¤.\"\n",
    "        #     ]\n",
    "        # },\n",
    "        {\n",
    "            \"title\": \"ìœ íŠœë¸Œ ë‚˜ì¤‘ì— ë³¼ ë™ì˜ìƒ ì—¬ë¶€ í…ŒìŠ¤íŠ¸\",\n",
    "            \"steps\": [\n",
    "                \"https://www.youtube.com ì— ì ‘ì†í•œë‹¤\",\n",
    "                \"ì™¼ìª½ì˜ ë„¤ë¹„ê²Œì´ì…˜ ë°”ì—ì„œ 'ê¹€ì •ìš°'ë¥¼ í´ë¦­í•œë‹¤.\",\n",
    "                \"ìŠ¤í¬ë¦°ìƒ·ì„ ì°ëŠ”ë‹¤\"\n",
    "            ]\n",
    "        },\n",
    "        # {\n",
    "        #     \"title\": \"ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\",\n",
    "        #     \"steps\": [\n",
    "        #         \"https://www.youtube.com ì— ì ‘ì†í•œë‹¤.\",\n",
    "        #         \"'lofi hip hop'ì„ ê²€ìƒ‰ì°½ì— ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥¸ë‹¤.\",\n",
    "        #         \"ìŠ¤í¬ë¦°ìƒ·ì„ ì°ì–´ì¤˜\"\n",
    "        #     ]\n",
    "        # },\n",
    "        # {\n",
    "        #     \"title\": \"ë¼í”„í…” í™”ë©´ ìº¡ì³ í…ŒìŠ¤íŠ¸\",\n",
    "        #     \"steps\": [\n",
    "        #         \"https://laftel.net/ ì— ì ‘ì†í•œë‹¤.\",\n",
    "        #         \"ì ‘ì† í™”ë©´ì„ ìŠ¤í¬ë¦°ìƒ· ì°ì–´ì¤˜\",\n",
    "        #         \"ìƒë‹¨ íƒ­ì—ì„œ 'ìš”ì¼ë³„ ì‹ ì‘'ì„ í´ë¦­í•´\",\n",
    "        #         \"í™”ë©´ì—ì„œ 'ìˆ˜ìš”ì¼'ë¶€ë¶„ ì•„ë˜ì— ìˆëŠ” ì²«ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ í´ë¦­í•´\",\n",
    "        #         \"í™”ë©´ì„ ìŠ¤í¬ë¦°ìƒ· ì°ì–´ì¤˜\"\n",
    "        #     ]\n",
    "        # }\n",
    "    ]\n",
    "\n",
    "    for i, scenario in enumerate(scenarios, 1):\n",
    "        agent = create_react_agent(model, tools)\n",
    "        await run_scenario(agent, scenario, i)\n",
    "\n",
    "    print(\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ:\", output_dir)\n",
    "\n",
    "# ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰\n",
    "async def run_scenario(agent, scenario: dict, index: int):\n",
    "    scenario_dir = os.path.join(output_dir, str(index))\n",
    "    screenshot_dir = os.path.join(scenario_dir, \"screenshots\")\n",
    "    os.makedirs(screenshot_dir, exist_ok=True)\n",
    "\n",
    "    screenshots, log_text = await run_with_callback(agent, scenario[\"steps\"], screenshot_dir)\n",
    "    summary = await summarize_result(log_text)\n",
    "    save_result(scenario, summary, screenshots, scenario_dir)\n",
    "\n",
    "# MCP ì‹¤í–‰ + ì½œë°± ìˆ˜ì§‘\n",
    "async def run_with_callback(agent, steps: list[str], screenshot_dir: str):\n",
    "    collected_text_chunks = []\n",
    "    screenshot_files = []\n",
    "\n",
    "    async def callback(event: dict[str, Any]):\n",
    "        content = event[\"content\"]\n",
    "\n",
    "        # ìŠ¤í¬ë¦°ìƒ·ì€ ToolMessageë¡œ, artifact ì•ˆì— ë“¤ì–´ìˆëŠ” base64 image\n",
    "        if isinstance(content, ToolMessage) and getattr(content, \"artifact\", None):\n",
    "            for artifact in content.artifact:\n",
    "                if getattr(artifact, \"type\", \"\") == \"image\" and hasattr(artifact, \"data\"):\n",
    "                    filename = f\"{len(screenshot_files)+1}.png\"\n",
    "                    filepath = os.path.join(screenshot_dir, filename)\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(base64.b64decode(artifact.data))\n",
    "                    screenshot_files.append(filename)\n",
    "                    print(f\"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ë¨: {filename}\")\n",
    "        else:\n",
    "            text = content.content if hasattr(content, \"content\") else str(content)\n",
    "            collected_text_chunks.append(text)\n",
    "\n",
    "    from utils import astream_graph\n",
    "    instruction = \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(steps + [DEFAULT_RESULT_STEP]))\n",
    "    await astream_graph(agent, inputs={\"messages\": instruction}, stream_mode=\"messages\", callback=callback)\n",
    "    return screenshot_files, \"\\n\".join(collected_text_chunks)\n",
    "\n",
    "# ìš”ì•½ ì²˜ë¦¬\n",
    "async def summarize_result(raw_text: str) -> WebTestResult:\n",
    "    return await summary_chain.ainvoke({\"raw_result\": raw_text})\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "def save_result(scenario: dict, result: WebTestResult, screenshots: List[str], scenario_dir: str):\n",
    "    result_json = {\n",
    "        \"title\": scenario[\"title\"],\n",
    "        \"status\": result.status,\n",
    "        \"duration\": result.duration,\n",
    "        \"feedback\": result.feedback,\n",
    "        \"fail\": [f.model_dump() for f in result.fail] if result.fail else None,\n",
    "        \"screenshots\": screenshots\n",
    "    }\n",
    "    with open(os.path.join(scenario_dir, \"result.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await run_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
