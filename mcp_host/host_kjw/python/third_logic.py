#!/usr/bin/env python3
import os
import sys
import json
import base64
import argparse
import asyncio

from datetime import datetime
from typing import List, Optional, Any, Dict

from dotenv import load_dotenv
from pydantic import BaseModel
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import ToolMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_core.runnables import Runnable
from utils import astream_graph

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv(override=True)

# ëª¨ë¸ ì„¸íŒ…
model = ChatAnthropic(model="claude-3-5-haiku-latest", temperature=0, max_tokens=1000)

# ê²°ê³¼ íŒŒì„œ
class FailedStep(BaseModel):
    num: int
    message: str

class WebTestResult(BaseModel):
    status: bool
    duration: Optional[float]
    feedback: str
    fail: Optional[List[FailedStep]]

parser = PydanticOutputParser(pydantic_object=WebTestResult)

summary_prompt = PromptTemplate(
    template="""
ë„ˆëŠ” ì›¹ í…ŒìŠ¤íŠ¸ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì…ë‹ˆë‹¤:
{raw_result}

ì´ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í¬ë§·ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:
{format_instructions}
""".strip(),
    input_variables=["raw_result"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)
summary_chain: Runnable = summary_prompt | model | parser

DEFAULT_RESULT_STEP = "ì„±ê³µ ì—¬ë¶€, ì†ë„, í”¼ë“œë°±ì„ í¬í•¨í•´ ê²°ê³¼ë¥¼ ìš”ì•½í•œë‹¤."

# ì½œë°± ì •ì˜
def handle_callback(
        event: Dict[str, Any],
        screenshot_dir: str,
        screenshot_files: List[str],
        collected_logs: List[str],
):
    content = event.get("content")
    if isinstance(content, ToolMessage) and getattr(content, "artifact", None):
        for artifact in content.artifact:
            if getattr(artifact, "type", "") == "image" and hasattr(artifact, "data"):
                filename = f"{len(screenshot_files)+1}.png"
                filepath = os.path.join(screenshot_dir, filename)
                with open(filepath, "wb") as f:
                    f.write(base64.b64decode(artifact.data))
                screenshot_files.append(filename)
                print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ë¨: {filename}")
    else:
        text = getattr(content, "content", str(content))
        if isinstance(text, list):
            collected_logs.extend(str(t) for t in text)
        else:
            collected_logs.append(str(text))

# MCP ì‹¤í–‰ + ì½œë°± ìˆ˜ì§‘
def create_instruction(steps: List[str]) -> str:
    return "\n".join(
        f"{i+1}. {step}" for i, step in enumerate(steps + [DEFAULT_RESULT_STEP])
    )

async def run_with_callback(agent, steps: List[str], screenshot_dir: str):
    collected_logs: List[str] = []
    screenshot_files: List[str] = []
    instruction = create_instruction(steps)

    await astream_graph(
        agent,
        inputs={"messages": instruction},
        stream_mode="messages",
        callback=lambda event: handle_callback(
            event, screenshot_dir, screenshot_files, collected_logs
        ),
    )

    return screenshot_files, "\n".join(collected_logs)

# ìš”ì•½
async def summarize_result(raw_text: str) -> WebTestResult:
    return await summary_chain.ainvoke({"raw_result": raw_text})

# ê²°ê³¼ ì €ì¥
def save_result(
        scenario: dict, result: WebTestResult, screenshots: List[str], scenario_dir: str
):
    result_json = {
        "title": scenario.get("title"),
        "status": result.status,
        "duration": result.duration,
        "feedback": result.feedback,
        "fail": [f.model_dump() for f in result.fail] if result.fail else None,
        "screenshots": screenshots,
    }
    os.makedirs(scenario_dir, exist_ok=True)
    with open(os.path.join(scenario_dir, "result.json"), "w", encoding="utf-8") as f:
        json.dump(result_json, f, ensure_ascii=False, indent=2)

# ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
async def run_scenario(agent, scenario: dict, index: int, output_dir: str):
    scenario_dir = os.path.join(output_dir, str(index))
    screenshot_dir = os.path.join(scenario_dir, "screenshots")
    os.makedirs(screenshot_dir, exist_ok=True)

    screenshots, log_text = await run_with_callback(
        agent, scenario.get("steps", []), screenshot_dir
    )

    summary = await summarize_result(log_text)
    save_result(scenario, summary, screenshots, scenario_dir)

# ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def run_test(scenarios: List[dict], build_num: int, base_dir: str):
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    test_id = f"{timestamp}_report_{build_num}"
    output_dir = os.path.join(base_dir, test_id)
    os.makedirs(output_dir, exist_ok=True)

    async with MultiServerMCPClient(
            {
                "playwright": {
                    "url": "http://localhost:8005/sse",
                    "transport": "sse",
                }
            }
    ) as client:
        tools = client.get_tools()
        for idx, scenario in enumerate(scenarios, start=1):
            agent = create_react_agent(model, tools)
            await run_scenario(agent, scenario, idx, output_dir)

    print(f"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {output_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--file", type=str, required=True, help="ì‹œë‚˜ë¦¬ì˜¤ JSON íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument("--build", type=int, required=True, help="ë¹Œë“œ ë²ˆí˜¸")
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./results",
        help="ê²°ê³¼ê°€ ì €ì¥ë  Base Directory",
    )
    args = parser.parse_args()

    # íŒŒì¼ ì½ê¸°: {"title": "...", "scenarios": [ {...}, {...} ]}
    with open(args.file, "r", encoding="utf-8") as f:
        data = json.load(f)
    scenarios = data.get("scenarios", [])

    # ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬
    asyncio.run(run_test(scenarios, build_num=args.build, base_dir=args.output_dir))
