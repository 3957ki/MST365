{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ./results\\20250422-122519_ff2329\\result.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import astream_graph  # ê¸°ì¡´ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# MCP ì„œë²„ ì—°ê²°\n",
    "client = MultiServerMCPClient({\n",
    "    \"playwright\": {\n",
    "        \"url\": \"http://localhost:8005/sse\",\n",
    "        \"transport\": \"sse\",\n",
    "    }\n",
    "})\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "BASE_DIR = \"./results\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "test_id = f\"{timestamp}_{uuid4().hex[:6]}\"\n",
    "output_dir = os.path.join(BASE_DIR, test_id)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Pydantic ëª¨ë¸ + íŒŒì„œ\n",
    "class WebTestResult(BaseModel):\n",
    "    success: bool = Field(..., description=\"ì„±ê³µ ì—¬ë¶€\")\n",
    "    duration: Optional[float] = Field(..., description=\"í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì‹œê°„\")\n",
    "    feedback: str = Field(..., description=\"ì›¹í˜ì´ì§€ ìƒíƒœ í”¼ë“œë°±\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=WebTestResult)\n",
    "\n",
    "# ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ë‹¤ìŒ ì›¹ ìë™í™” í…ŒìŠ¤íŠ¸ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì•„ë˜ í˜•ì‹ì˜ JSONìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n",
    "{format_instructions}\n",
    "\n",
    "ë¡œê·¸:\n",
    "{raw_result}\n",
    "\"\"\",\n",
    "    input_variables=[\"raw_result\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "summary_chain: Runnable = summary_prompt | model | parser\n",
    "\n",
    "# ğŸ”„ ë¡œê·¸ ëˆ„ì  ë¦¬ìŠ¤íŠ¸\n",
    "collected_text_chunks = []\n",
    "\n",
    "# ì½œë°± í•¨ìˆ˜ì—ì„œ ë¡œê·¸ ìˆ˜ì§‘\n",
    "async def collect_text(event: dict):\n",
    "    content = event[\"content\"]\n",
    "    if hasattr(content, \"content\"):\n",
    "        collected_text_chunks.append(content.content)\n",
    "    else:\n",
    "        collected_text_chunks.append(str(content))\n",
    "\n",
    "# ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜\n",
    "async def run_test():\n",
    "    await client.__aenter__()\n",
    "    tools = client.get_tools()\n",
    "    agent = create_react_agent(model, tools)\n",
    "\n",
    "    # message ì •ì˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    message = {\n",
    "        \"scenarios\": [\n",
    "            {\n",
    "                \"title\": \"ë„¤ì´ë²„ ê²€ìƒ‰ ê¸°ëŠ¥ í™•ì¸\",\n",
    "                \"steps\": [\n",
    "                    \"https://naver.com ì— ì ‘ì†í•œë‹¤.\",\n",
    "                    \"ê²€ìƒ‰ì°½ì— SSAFYë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰ë²„íŠ¼ì„ ëˆ„ë¥¸ë‹¤.\",\n",
    "                    \"SSAFYì™€ ê´€ë ¨ëœ ê²Œì‹œë¬¼ì´ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•œë‹¤.\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"êµ¬ê¸€ì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\",\n",
    "                \"steps\": [\n",
    "                    \"https://www.google.com ì— ì ‘ì†í•œë‹¤.\",\n",
    "                    \"'cute cats'ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒë‹¨ íƒ­ì—ì„œ 'ì´ë¯¸ì§€'ë¥¼ í´ë¦­í•œë‹¤.\",\n",
    "                    \"ì´ë¯¸ì§€ ì¸ë„¤ì¼ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë”©ë˜ëŠ”ì§€ í™•ì¸í•œë‹¤.\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\",\n",
    "                \"steps\": [\n",
    "                    \"https://www.youtube.com ì— ì ‘ì†í•œë‹¤.\",\n",
    "                    \"'lofi hip hop'ì„ ê²€ìƒ‰ì°½ì— ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥¸ë‹¤.\",\n",
    "                    \"ê²€ìƒ‰ ê²°ê³¼ì— ì¸ë„¤ì¼ê³¼ ì œëª©ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•œë‹¤.\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    DEFAULT_RESULT_STEP = \"ì„±ê³µ ì—¬ë¶€, ì†ë„, í”¼ë“œë°±ì„ í¬í•¨í•´ ê²°ê³¼ë¥¼ ìš”ì•½í•œë‹¤.\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ë“¤ì„ ìì—°ì–´ ë©”ì‹œì§€ë¡œ ë³€í™˜\n",
    "    for scenario in message[\"scenarios\"]:\n",
    "        # ê° ì‹œë‚˜ë¦¬ì˜¤ ë©”ì‹œì§€ êµ¬ì„±\n",
    "        steps = scenario[\"steps\"] + [DEFAULT_RESULT_STEP]\n",
    "        steps_text = \"\\n\".join([f\"{i+1}. {step}\" for i, step in enumerate(steps)])\n",
    "        messages = f\"### {scenario['title']}\\n{steps_text}\"\n",
    "\n",
    "        # ë¡œê·¸ ëˆ„ì  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        collected_text_chunks.clear()\n",
    "\n",
    "        # LangGraph ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ë¡œê·¸ ìˆ˜ì§‘)\n",
    "        await astream_graph(\n",
    "            agent,\n",
    "            inputs={\"messages\": messages},\n",
    "            stream_mode=\"messages\",\n",
    "            callback=collect_text\n",
    "        )\n",
    "\n",
    "        joined_result = \"\\n\".join(collected_text_chunks)\n",
    "\n",
    "        # ìš”ì•½ ê²°ê³¼ ìƒì„±\n",
    "        parsed = await summary_chain.ainvoke({\"raw_result\": joined_result})\n",
    "\n",
    "        # ì €ì¥í•  í˜•íƒœë¡œ ì¶”ê°€\n",
    "        results.append({\n",
    "            \"title\": scenario[\"title\"],\n",
    "            \"success\": parsed.success,\n",
    "            \"duration\": parsed.duration,\n",
    "            \"feedback\": parsed.feedback\n",
    "        })\n",
    "\n",
    "\n",
    "    # ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "    result_json_path = os.path.join(output_dir, \"result.json\")\n",
    "    with open(result_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\", result_json_path)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await run_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
